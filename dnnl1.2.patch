diff --git a/include/ideep/abstract_types.hpp b/include/ideep/abstract_types.hpp
index c67f466..9918b59 100644
--- a/include/ideep/abstract_types.hpp
+++ b/include/ideep/abstract_types.hpp
@@ -104,8 +104,8 @@ const std::map<data_type, int> dt_max_map
 };
 
 enum lowp_kind {
-  u8s8 = 0,
-  s8s8 = 1
+  LOWP_U8S8 = 0,
+  LOWP_S8S8 = 1
 };
 
 enum rnn_kind {
diff --git a/include/ideep/attributes.hpp b/include/ideep/attributes.hpp
index e4bde06..4ba0ee5 100644
--- a/include/ideep/attributes.hpp
+++ b/include/ideep/attributes.hpp
@@ -7,27 +7,27 @@ namespace ideep {
 
 struct post_ops : public dnnl::post_ops {
 
-  bool has_op_kind(dnnl::primitive::kind op_kind) const {
-    for (int i = 0; i < len(); i++)
-      if (op_kind == kind(i))
-        return true;
-    return false;
-  }
-
-  bool non_negitive_output() const {
-    // auto last = len() - 1;
-    // if (last < 0) {
-    //   return false;
-    // }
-
-    // auto params = get_params(last);
-    // if (std::get<0>(params) != kind::eltwise || std::get<1>(params) <= 0.f ||
-    //     std::get<2>(params) != 0.f || std::get<3>(params) != 0.f ||
-    //     std::get<4>(params) != algorithm::eltwise_relu)
-    //   return false;
-
-    // return true;
-  }
+  // bool has_op_kind(dnnl::primitive::kind op_kind) const {
+  //   for (int i = 0; i < len(); i++)
+  //     if (op_kind == kind(i))
+  //       return true;
+  //   return false;
+  // }
+
+  // bool non_negitive_output() const {
+  //   // auto last = len() - 1;
+  //   // if (last < 0) {
+  //   //   return false;
+  //   // }
+
+  //   // auto params = get_params(last);
+  //   // if (std::get<0>(params) != kind::eltwise || std::get<1>(params) <= 0.f ||
+  //   //     std::get<2>(params) != 0.f || std::get<3>(params) != 0.f ||
+  //   //     std::get<4>(params) != algorithm::eltwise_relu)
+  //   //   return false;
+
+  //   // return true;
+  // }
 };
 
 /// Attribute class for extra information into computations
@@ -67,7 +67,6 @@ public:
     return attr;
   }
 
-
   static inline attr_t residual(float sum_scale = 1.0, float relu_scale = 1.0,
                                 float alpha = 0.f, float beta = 0.f) {
     attr_t attr;
@@ -83,8 +82,64 @@ public:
     attr.set_post_ops(po);
     return attr;
   }
+
+  inline bool has_op_kind(dnnl::primitive::kind op_kind) const {
+    auto po = get_post_ops();
+    for (int i = 0; i < po.len(); i++)
+      if (op_kind == po.kind(i))
+        return true;
+    return false;
+  }
+
+  inline std::tuple<dnnl::primitive::kind, float, float, float, algorithm> get_params (
+      int index) const {
+    auto po = get_post_ops();
+    IDEEP_ENFORCE(index < po.len(), "post_ops index is out of range");
+
+    dnnl_alg_kind_t c_alg = dnnl_eltwise_relu;
+    float scale = 1.0, alpha = 1.0, beta = 0.0;
+
+    // auto akind = op_kind(index);
+    auto akind = static_cast<dnnl::primitive::kind>(
+        dnnl_post_ops_get_kind(po.get(), index));
+    switch (akind) {
+      case kind::sum:
+        error::wrap_c_api(
+            dnnl_post_ops_get_params_sum(po.get(), index, &scale),
+            "could not get sum params");
+        break;
+      case kind::eltwise:
+        error::wrap_c_api(
+            dnnl_post_ops_get_params_eltwise(
+                po.get(), index, &scale, &c_alg, &alpha, &beta),
+            "could not get eltwise params");
+        break;
+      default:
+        error::wrap_c_api(dnnl_invalid_arguments, "could not get params");
+        break;
+    }
+
+    return std::make_tuple(
+        akind, scale, alpha, beta, static_cast<algorithm>(c_alg));
+  }
+
+  inline bool non_negitive_output() const {
+    auto po = get_post_ops();
+    auto last = po.len() - 1;
+    if (last < 0) {
+      return false;
+    }
+
+    auto params = get_params(last);
+    if (std::get<0>(params) != kind::eltwise || std::get<1>(params) <= 0.f ||
+        std::get<2>(params) != 0.f || std::get<3>(params) != 0.f ||
+        std::get<4>(params) != algorithm::eltwise_relu)
+      return false;
+
+    return true;
+  }
 };
 
 }  // namespace ideep
 
-#endif
\ No newline at end of file
+#endif
diff --git a/include/ideep/operators/conv.hpp b/include/ideep/operators/conv.hpp
index 58be570..654358c 100644
--- a/include/ideep/operators/conv.hpp
+++ b/include/ideep/operators/conv.hpp
@@ -8,47 +8,89 @@ struct convolution_forward : public dnnl::convolution_forward {
   using super = dnnl::convolution_forward;
 
   // fp32 w/ bias
-  static void compute(const tensor& src,
-                      const tensor& weights,
-                      const tensor& bias,
-                      const dims& dst_dims,
-                      tensor& dst,
-                      const dims& strides,
-                      const dims& dilates,
-                      const dims& padding_l,
-                      const dims& padding_r,
-                      int groups,
-                      const attr_t& attr = attr_t(),
-                      algorithm aalgorithm = algorithm::convolution_direct,
-                      prop_kind aprop_kind = prop_kind::forward,
-                      const engine& aengine = engine::cpu_engine()) {
+  static void compute(
+      const tensor& src,
+      const tensor& weights,
+      const tensor& bias,
+      const dims& dst_dims,
+      tensor& dst,
+      const dims& strides,
+      const dims& dilates,
+      const dims& padding_l,
+      const dims& padding_r,
+      int groups,
+      const scale_t& src_scales = scale_t(),
+      const scale_t& weights_scales = scale_t(),
+      const scale_t& dst_scales = scale_t(),
+      const attr_t& attr = attr_t(),
+      algorithm aalgorithm = algorithm::convolution_direct,
+      prop_kind aprop_kind = prop_kind::forward,
+      const lowp_kind alowp_kind = LOWP_U8S8,
+      const engine& aengine = engine::cpu_engine()) {
     compute_impl</*with_bias=*/true>(
-        src, weights, bias, dst_dims, dst, strides, dilates,
-        padding_l, padding_r, groups, attr, aalgorithm, aprop_kind, aengine);
+        src,
+        weights,
+        bias,
+        dst_dims,
+        dst,
+        strides,
+        dilates,
+        padding_l,
+        padding_r,
+        groups,
+        src_scales,
+        weights_scales,
+        dst_scales,
+        attr,
+        aalgorithm,
+        aprop_kind,
+        alowp_kind,
+        aengine);
   }
 
   // fp32 w/o bias
-  static void compute(const tensor& src,
-                      const tensor& weights,
-                      const dims& dst_dims,
-                      tensor& dst,
-                      const dims& strides,
-                      const dims& dilates,
-                      const dims& padding_l,
-                      const dims& padding_r,
-                      int groups,
-                      const attr_t& attr = attr_t(),
-                      algorithm aalgorithm = algorithm::convolution_direct,
-                      prop_kind aprop_kind = prop_kind::forward,
-                      const engine& aengine = engine::cpu_engine()) {
+  static void compute(
+      const tensor& src,
+      const tensor& weights,
+      const dims& dst_dims,
+      tensor& dst,
+      const dims& strides,
+      const dims& dilates,
+      const dims& padding_l,
+      const dims& padding_r,
+      int groups,
+      const scale_t& src_scales = scale_t(),
+      const scale_t& weights_scales = scale_t(),
+      const scale_t& dst_scales = scale_t(),
+      const attr_t& attr = attr_t(),
+      algorithm aalgorithm = algorithm::convolution_direct,
+      prop_kind aprop_kind = prop_kind::forward,
+      const lowp_kind alowp_kind = LOWP_U8S8,
+      const engine& aengine = engine::cpu_engine()) {
     static tensor dummy_bias;
     compute_impl</*with_bias=*/false>(
-        src, weights, dummy_bias, dst_dims, dst, strides, dilates,
-        padding_l, padding_r, groups, attr, aalgorithm, aprop_kind, aengine);
+        src,
+        weights,
+        dummy_bias,
+        dst_dims,
+        dst,
+        strides,
+        dilates,
+        padding_l,
+        padding_r,
+        groups,
+        src_scales,
+        weights_scales,
+        dst_scales,
+        attr,
+        aalgorithm,
+        aprop_kind,
+        alowp_kind,
+        aengine);
   }
 
   // TODO: XPZ: refactor it
-  static memory::desc expected_weights_desc(
+  static memory::desc expected_weights_descriptor(
       const dims& weights_dims,
       data_type dtype = data_type::f32,
       const dims& strides = {1, 1},
@@ -173,32 +215,123 @@ private:
                            const dims& padding_l,
                            const dims& padding_r,
                            int groups,
+                           const scale_t& src_scales,
+                           const scale_t& weights_scales,
+                           const scale_t& dst_scales,
                            const attr_t& attr,
                            algorithm aalgorithm,
                            prop_kind aprop_kind,
+                           const lowp_kind alowp_kind,
                            const engine& aengine) {
+    scale_t dst_scales_in;
+    auto dst_data_type = data_type::f32;
+    tensor::desc src_desc, weights_desc, bias_desc;
+    attr_t op_attr, src_attr, weights_attr, bias_attr;
 
     // make weights and dilates compatible with DNNL
     auto weights_ = weights.make_grouped_weights(groups);
     auto dilates_ = utils::get_compatible_dilates(dilates);
 
+    auto weights_scales_in = weights_.has_scale() ? weights_.get_scale() : weights_scales;
+    if (!weights_scales_in.empty()) {
+      IDEEP_ENFORCE(alowp_kind == LOWP_U8S8 || alowp_kind == LOWP_S8S8, "Unsupported lowp kind");
+      int scale_size = (weights_scales_in.size() > 1) ? dst_dims[1] : 1;
+      auto src_scales_in = src.has_scale() ? src.get_scale()
+        : (src_scales.empty() ? IDEEP_DEF_SCALE : src_scales);
+
+      // determine dst data type
+      if (attr.has_op_kind(kind::sum)) {
+        dst_data_type = dst.get_data_type();
+      } else if (dst_scales.empty() || dst_scales == IDEEP_DEF_SCALE) {
+        dst_data_type = data_type::f32;
+      } else if (attr.non_negitive_output()){
+        dst_data_type = data_type::u8;
+      } else {
+        dst_data_type = data_type::s8;
+      }
+
+      // fill primitive attr
+      scale_t op_scales(scale_size), bias_scales(scale_size);
+      dst_scales_in = (dst_scales.empty() || dst_data_type == data_type::f32)
+        ? IDEEP_DEF_SCALE : dst_scales;
+      for (int i = 0; i < scale_size; i++) {
+        bias_scales[i] = src_scales_in[0] * weights_scales_in[i];
+        op_scales[i] = dst_scales_in[0] / bias_scales[i];
+      }
+
+      if (attr.has_op_kind(kind::sum)) {
+        float sum_scale = dst_scales_in[0] / (dst.has_scale() ? dst.get_scale()[0] : 1.0f);
+        if (attr.has_op_kind(kind::eltwise)) {
+          op_attr = attr_t::residual(sum_scale);
+        } else {
+          op_attr = attr_t::fuse_sum(sum_scale);
+        }
+      } else if (attr.has_op_kind(kind::eltwise)) {
+        op_attr = attr_t::fuse_relu();
+      }
+      op_attr.set_output_scales(IDEEP_OP_SCALE_MASK(scale_size), op_scales);
+      // op_attr.set_int_output_round_mode(round_mode::round_nearest);
+
+      src_desc = {src.get_dims(), alowp_kind == LOWP_U8S8 ? data_type::u8 : data_type::s8, format_tag::any};
+      if (src.get_data_type() == data_type::f32) {
+        src_attr = {0 , src_scales_in};
+      }
+
+      weights_desc = {weights_.get_dims(), data_type::s8, format_tag::any};
+      if (weights_.get_data_type() == data_type::f32) {
+        weights_attr = {IDEEP_TENSOR_SCALE_MASK(scale_size, (groups > 1)), weights_scales_in};
+      }
+
+      if (with_bias) {
+        bias_desc = {bias.get_dims(), data_type::s32, format_tag::any};
+        if (bias.get_data_type() == data_type::f32) {
+          bias_attr = {IDEEP_TENSOR_SCALE_MASK(scale_size, false), bias_scales};
+        }
+      }
+    } else {
+      op_attr = attr;
+
+      src_desc = {src.get_dims(), data_type::f32, format_tag::any};
+      if (src.has_scale()) {
+        auto src_scale = src.get_scale();
+        src_scale[0] = 1.0f / src_scale[0];
+        src_attr = {0, src_scale};
+      }
+
+      weights_desc = weights_.get_desc().to_format_any();
+      IDEEP_ENFORCE(weights_.get_data_type() == data_type::f32, "Incorrect data type in weights");
+
+      if (with_bias) {
+        IDEEP_ENFORCE(bias.get_data_type() == data_type::f32, "Incorrect data type in bias");
+        bias_desc = bias.get_desc().to_format_any();
+      }
+    }
+
     // TODO: XPZ: is it ok to use src type as dst type?
-    tensor::desc dst_desc(dst_dims, src.get_data_type());
+    tensor::desc dst_desc;
+    if (attr.has_op_kind(kind::sum))
+      dst_desc = dst.get_desc();
+    else
+      dst_desc = {dst_dims, dst_data_type, format_tag::any};
 
     auto pd = get_primitive_desc<with_bias>(
-        src.get_desc(), weights_.get_desc(), bias.get_desc(), dst_desc,
+        src_desc, weights_desc, bias_desc, dst_desc,
         strides, dilates_, padding_l, padding_r, attr, aalgorithm,
         aprop_kind, aengine);
 
-    auto expected_src = src.reorder_if_necessary(pd.src_desc());
-    auto expected_weights = weights_.reorder_if_necessary(pd.weights_desc());
+    auto expected_src = src.reorder_if_necessary(pd.src_desc(), src_attr);
+    auto expected_weights = weights_.reorder_if_necessary(pd.weights_desc(), weights_attr);
     dst.reinit_if_necessary(pd.dst_desc());
+    if (!dst_scales.empty() && dst_data_type != data_type::f32) {
+      dst.set_scale(dst_scales_in);
+    }
 
     if (with_bias) {
+      auto expected_bias = bias.reorder_if_necessary(pd.bias_desc(), bias_attr);
       super(pd).execute(stream::default_stream(), 
                         {{DNNL_ARG_SRC, expected_src},
                          {DNNL_ARG_WEIGHTS, expected_weights},
-                         {DNNL_ARG_BIAS, bias},
+                         {DNNL_ARG_BIAS, expected_bias},
                          {DNNL_ARG_DST, dst}});
     } else {
       super(pd).execute(stream::default_stream(), 
@@ -206,6 +339,11 @@ private:
                          {DNNL_ARG_WEIGHTS, expected_weights},
                          {DNNL_ARG_DST, dst}});
     }
+
+    // if (attr.non_negitive_output() && dst.get_data_type() == data_type::s8) {
+    //   tensor::desc dst_u8_desc = dst.get_desc().to_type(data_type::u8);
+    //   dst.set_desc(dst_u8_desc);
+    // }
   }
 
   // static dims infer_output_size(const tensor::desc& input_desc,
diff --git a/include/ideep/operators/deconv.hpp b/include/ideep/operators/deconv.hpp
index 37d8c39..0200336 100644
--- a/include/ideep/operators/deconv.hpp
+++ b/include/ideep/operators/deconv.hpp
@@ -8,24 +8,24 @@ struct convolution_transpose_forward : public dnnl::deconvolution_forward {
   static void compute(const tensor& src,
                       const tensor& weights,
                       const tensor& bias,
-                      const tdims_t& result_dims,
+                      const dims& result_dims,
                       tensor& dst,
-                      const tdims_t& strides,
-                      const tdims_t& padding_l,
-                      const tdims_t& padding_r,
-                      const tdims_t& dilates = {1, 1},
+                      const dims& strides,
+                      const dims& padding_l,
+                      const dims& padding_r,
+                      const dims& dilates = {1, 1},
                       const attr_t& attr = attr_t(),
                       algorithm aalgorithm = algorithm::deconvolution_direct,
                       prop_kind aprop_kind = prop_kind::forward) {}
 
   static void compute(const tensor& src,
                       const tensor& weights,
-                      const tdims_t& result_dims,
+                      const dims& result_dims,
                       tensor& dst,
-                      const tdims_t& strides,
-                      const tdims_t& padding_l,
-                      const tdims_t& padding_r,
-                      const tdims_t& dilates = {1, 1},
+                      const dims& strides,
+                      const dims& padding_l,
+                      const dims& padding_r,
+                      const dims& dilates = {1, 1},
                       const attr_t& attr = attr_t(),
                       algorithm aalgorithm = algorithm::deconvolution_direct,
                       prop_kind aprop_kind = prop_kind::forward) {}
@@ -34,9 +34,9 @@ struct convolution_transpose_forward : public dnnl::deconvolution_forward {
 struct convolution_transpose_backward_data
     : public dnnl::deconvolution_backward_data {
   static void compute(const tensor& grady, const tensor& weights,
-                      const tdims_t& gradx_dims, tensor& gradx,
-                      const tdims_t& strides, const tdims_t& padding_l,
-                      const tdims_t& padding_r, const tdims_t& dilates = {1, 1},
+                      const dims& gradx_dims, tensor& gradx,
+                      const dims& strides, const dims& padding_l,
+                      const dims& padding_r, const dims& dilates = {1, 1},
                       algorithm aalgorithm = algorithm::deconvolution_direct) {}
 };
 
@@ -44,18 +44,18 @@ struct convolution_transpose_backward_weights
     : public dnnl::deconvolution_backward_weights {
   template <bool with_gradb = true>
   static void compute(const tensor& src, const tensor& grady,
-                      const tdims_t& gradw_dims, tensor& gradw, tensor& gradb,
-                      const tdims_t& strides, const tdims_t& padding_l,
-                      const tdims_t& padding_r, const tdims_t& dilates = {1, 1},
+                      const dims& gradw_dims, tensor& gradw, tensor& gradb,
+                      const dims& strides, const dims& padding_l,
+                      const dims& padding_r, const dims& dilates = {1, 1},
                       algorithm aalgorithm = algorithm::deconvolution_direct) {}
 
   static void compute(const tensor& src, const tensor& grady,
-                      const tdims_t& gradw_dims, tensor& gradw,
-                      const tdims_t& strides, const tdims_t& padding_l,
-                      const tdims_t& padding_r, const tdims_t& dilates = {1, 1},
+                      const dims& gradw_dims, tensor& gradw,
+                      const dims& strides, const dims& padding_l,
+                      const dims& padding_r, const dims& dilates = {1, 1},
                       algorithm aalgorithm = algorithm::deconvolution_direct) {}
 };
 
 }  // namespace ideep
 
-#endif
\ No newline at end of file
+#endif
diff --git a/include/ideep/operators/inner_product.hpp b/include/ideep/operators/inner_product.hpp
index 8abf40c..d431a4e 100644
--- a/include/ideep/operators/inner_product.hpp
+++ b/include/ideep/operators/inner_product.hpp
@@ -7,55 +7,218 @@ struct inner_product_forward : public dnnl::inner_product_forward {
 
   using super = dnnl::inner_product_forward;
   template <bool with_bias = true>
-  static void compute(const tensor& src,
-                      const tensor& weights,
-                      const tensor& bias,
-                      tensor& dst,
-                      prop_kind aprop_kind = prop_kind::forward,
-                      const engine& aengine = engine::cpu_engine()) {
-  compute_impl<with_bias>(src, weights, bias, dst, aprop_kind, aengine);
+  static void compute(
+      const tensor& src,
+      const tensor& weights,
+      const tensor& bias,
+      tensor& dst,
+      const scale_t& src_scales = scale_t(),
+      const scale_t& weights_scales = scale_t(),
+      const scale_t& dst_scales = scale_t(),
+      const attr_t& attr = attr_t(),
+      const prop_kind aprop_kind = prop_kind::forward,
+      const lowp_kind alowp_kind = LOWP_U8S8,
+      const engine& aengine = engine::cpu_engine()) {
+    compute_impl<with_bias>(
+        src,
+        weights,
+        bias,
+        dst,
+        src_scales,
+        weights_scales,
+        dst_scales,
+        attr,
+        aprop_kind,
+        alowp_kind,
+        aengine);
   }
 
-  static void compute(const tensor& src,
-                      const tensor& weights,
-                      tensor& dst,
-                      prop_kind aprop_kind = prop_kind::forward,
-                      const engine& aengine = engine::cpu_engine()) {
+  static void compute(
+      const tensor& src,
+      const tensor& weights,
+      tensor& dst,
+      const scale_t& src_scales = scale_t(),
+      const scale_t& weights_scales = scale_t(),
+      const scale_t& dst_scales = scale_t(),
+      const attr_t& attr = attr_t(),
+      const prop_kind aprop_kind = prop_kind::forward,
+      const lowp_kind alowp_kind = LOWP_U8S8,
+      const engine& aengine = engine::cpu_engine()) {
     static tensor dummy_bias;
-    compute<false>(src, weights, dummy_bias, dst, aprop_kind, aengine);
+    compute<false>(
+        src,
+        weights,
+        dummy_bias,
+        dst,
+        src_scales,
+        weights_scales,
+        dst_scales,
+        attr,
+        aprop_kind,
+        alowp_kind,
+        aengine);
+  }
+
+  static memory::desc expected_weights_descriptor(
+      const dims& weights_dims,
+      tensor::data_type dtype = tensor::data_type::f32,
+      tensor::data_type x_dtype = tensor::data_type::f32,
+      prop_kind aprop_kind = prop_kind::forward,
+      const engine& aengine = engine::cpu_engine()) {
+    auto x_dims = weights_dims;
+    x_dims[0] = 1;
+    auto y_dims = {x_dims[0], weights_dims[0]};
+    auto ndims = weights_dims.size();
+    auto y_dtype =
+        (dtype != tensor::data_type::s8) ? dtype : tensor::data_type::s32;
+
+    IDEEP_ENFORCE(
+        x_dims.size() == weights_dims.size(),
+        "Invalid dims for data and weights");
+    tensor::desc x_desc(
+        x_dims, x_dtype, ndims == 2 ? format_tag::nc : format_tag::nchw);
+    tensor::desc y_desc(y_dims, y_dtype, format_tag::nc);
+    tensor::desc weights_desc(
+        weights_dims, dtype, ndims == 2 ? format_tag::oi : format_tag::oihw);
+
+    auto pd =
+        primitive_desc({aprop_kind, x_desc, weights_desc, y_desc}, aengine);
+    return pd.weights_desc();
   }
 
 private:
-  template <bool with_bias = true>
-  static void compute_impl(const tensor& src,
-                           const tensor& weights,
-                           const tensor& bias,
-                           tensor& dst,
-                           prop_kind aprop_kind = prop_kind::forward,
-                           const engine& aengine = engine::cpu_engine()) {
-    auto src_desc = src.get_desc().to_format_any();
-    auto weights_desc = weights.get_desc().to_format_any();
-    auto bias_desc = with_bias ? bias.get_desc().to_format_any() : tensor::desc();
-    auto dst_desc = dst.get_desc().to_format_any();
-    auto pd = with_bias ? primitive_desc(
-        {aprop_kind, src_desc, weights_desc, bias_desc, dst_desc}, aengine)
-        : primitive_desc({aprop_kind, src_desc, weights_desc, dst_desc}, aengine);
-    auto expected_src = src.reorder_if_necessary(pd.src_desc());
-    auto expected_weights = weights.reorder_if_necessary(pd.weights_desc());
-    dst.reinit_if_necessary(pd.dst_desc());
-    if (with_bias){
-      auto expected_bias = bias.reorder_if_necessary(pd.bias_desc());
-      super(pd).execute(stream::default_stream(),
-                        {{DNNL_ARG_SRC, expected_src},
-                         {DNNL_ARG_WEIGHTS, expected_weights},
-                         {DNNL_ARG_BIAS, expected_bias},
-                         {DNNL_ARG_DST, dst}});
-    } else {
-      super(pd).execute(stream::default_stream(),
-                        {{DNNL_ARG_SRC, expected_src},
-                         {DNNL_ARG_WEIGHTS, expected_weights},
-                         {DNNL_ARG_DST, dst}});
-    }
+ template <bool with_bias = true>
+ static void compute_impl(
+     const tensor& src,
+     const tensor& weights,
+     const tensor& bias,
+     tensor& dst,
+     const scale_t& src_scales = scale_t(),
+     const scale_t& weights_scales = scale_t(),
+     const scale_t& dst_scales = scale_t(),
+     const attr_t& attr = attr_t(),
+     const prop_kind aprop_kind = prop_kind::forward,
+     const lowp_kind alowp_kind = LOWP_U8S8,
+     const engine& aengine = engine::cpu_engine()) {
+   IDEEP_ENFORCE(src.ndims() == weights.ndims(), "Invalid dims in src or weights");
+
+   tensor::desc src_desc, weights_desc, bias_desc;
+   attr_t op_attr, src_attr, weights_attr, bias_attr;
+   scale_t dst_scales_in;
+   auto dst_data_type = data_type::f32;
+   tensor::dims dst_dims;
+
+   auto weights_scales_in =
+       weights.has_scale() ? weights.get_scale() : weights_scales;
+
+   if (!weights_scales_in.empty()) {
+     IDEEP_ENFORCE(
+         alowp_kind == LOWP_U8S8 || alowp_kind == LOWP_S8S8,
+         "Unsupported lowp kind");
+
+     auto src_scales_in = src.has_scale()
+         ? src.get_scale()
+         : (src_scales.empty() ? IDEEP_DEF_SCALE : src_scales);
+
+     src_desc = {src.get_dims(),
+                 alowp_kind == LOWP_U8S8 ? data_type::u8 : data_type::s8,
+                 format_tag::any};
+     if (src.get_data_type() == data_type::f32) {
+       src_attr = {0, src_scales_in};
+     }
+
+     dst_dims = {src_desc.get_dim(0), weights.get_dim(0)};
+     int scale_size = (weights_scales_in.size() > 1) ? dst_dims[1] : 1;
+
+     weights_desc = {weights.get_dims(), data_type::s8, format_tag::any};
+     if (weights.get_data_type() == data_type::f32) {
+       weights_attr = {IDEEP_TENSOR_SCALE_MASK(scale_size, false), weights_scales_in};
+     }
+
+     // determine dst data type
+     if (dst_scales.empty() || dst_scales == IDEEP_DEF_SCALE) {
+       dst_data_type = data_type::f32;
+     } else if (attr.non_negitive_output()){
+       dst_data_type = data_type::u8;
+     } else {
+       dst_data_type = data_type::s8;
+     }
+
+     // fill primitive attr
+     scale_t op_scales(scale_size), bias_scales(scale_size);
+     dst_scales_in = (dst_scales.empty() || dst_data_type == data_type::f32) ? IDEEP_DEF_SCALE : dst_scales;
+     for (int i = 0; i < scale_size; i++) {
+       bias_scales[i] = src_scales_in[0] * weights_scales_in[i];
+       op_scales[i] = dst_scales_in[0] / bias_scales[i];
+     }
+     op_attr.set_output_scales(IDEEP_OP_SCALE_MASK(scale_size), op_scales);
+    //  op_attr.set_int_output_round_mode(round_mode::round_nearest);
+
+     if (with_bias) {
+       bias_desc = {bias.get_dims(), data_type::s32, format_tag::any};
+       if (bias.get_data_type() == data_type::f32) {
+         bias_attr = {IDEEP_TENSOR_SCALE_MASK(scale_size, false), bias_scales};
+       }
+     }
+   } else {
+     op_attr = attr;
+     src_desc = {src.get_dims(), data_type::f32, format_tag::any};
+     if (src.has_scale()) {
+       auto src_scale = src.get_scale();
+       src_scale[0] = 1.0f / src_scale[0];
+       src_attr = {0, src_scale};
+     }
+     dst_dims = {src_desc.get_dim(0), weights.get_dim(0)};
+     weights_desc = weights.get_desc().to_format_any();
+     IDEEP_ENFORCE(weights.get_data_type() == data_type::f32, "Incorrect data type in weights");
+     if (with_bias) {
+       IDEEP_ENFORCE(bias.get_data_type() == data_type::f32, "Incorrect data type in bias");
+       bias_desc = bias.get_desc().to_format_any();
+     }
+   }
+  //  auto src_desc_in = src_desc.to_format_any();
+  //  tensor::desc weights_desc_in;
+  //   if (weights_desc.get_data_type() == data_type::s8 ||
+  //       weights_desc.get_data_type() == data_type::u8)
+  //     weights_desc_in = weights_desc.to_format_any();
+  //   else
+  //     weights_desc_in = weights_desc;
+  //  auto bias_desc_in =
+  //      with_bias ? bias_desc.to_format_any() : tensor::desc();
+   tensor::desc dst_desc(dst_dims, dst_data_type, format_tag::any);
+   auto pd = with_bias
+       ? primitive_desc(
+             {aprop_kind, src_desc, weights_desc, bias_desc, dst_desc}, aengine)
+       : primitive_desc(
+             {aprop_kind, src_desc, weights_desc, dst_desc}, aengine);
+   auto expected_src = src.reorder_if_necessary(pd.src_desc(), src_attr);
+   auto expected_weights = weights.reorder_if_necessary(pd.weights_desc(), weights_attr);
+
+   dst.reinit_if_necessary(pd.dst_desc());
+   if (!dst_scales.empty() && dst_data_type != data_type::f32) {
+     dst.set_scale(dst_scales_in);
+   }
+
+   if (with_bias) {
+     auto expected_bias = bias.reorder_if_necessary(pd.bias_desc(), bias_attr);
+     super(pd).execute(
+         stream::default_stream(),
+         {{DNNL_ARG_SRC, expected_src},
+          {DNNL_ARG_WEIGHTS, expected_weights},
+          {DNNL_ARG_BIAS, expected_bias},
+          {DNNL_ARG_DST, dst}});
+   } else {
+     super(pd).execute(
+         stream::default_stream(),
+         {{DNNL_ARG_SRC, expected_src},
+          {DNNL_ARG_WEIGHTS, expected_weights},
+          {DNNL_ARG_DST, dst}});
+   }
+
+  //  if (attr.non_negitive_output() && dst.get_data_type() == data_type::s8) {
+  //    tensor::desc dst_u8_desc = dst.get_desc().to_type(data_type::u8);
+  //    dst.set_desc(dst_u8_desc);
+  //  }
   }
 };
 
diff --git a/include/ideep/tensor.hpp b/include/ideep/tensor.hpp
index cf76caa..b129584 100644
--- a/include/ideep/tensor.hpp
+++ b/include/ideep/tensor.hpp
@@ -607,12 +607,12 @@ class tensor : public memory {
     std::cout << std::endl;
   }
 
-  tensor reorder_if_necessary(const memory::desc &expected_desc) const {
+  tensor reorder_if_necessary(const memory::desc &expected_desc, const attr_t &aattr = attr_t()) const {
     if (expected_desc == get_desc()) {
       return *this;
     } else {
       tensor dst{expected_desc};
-      this->reorder_to(dst);
+      this->reorder_to(dst, aattr);
       return dst;
     }
   }
