diff --git a/include/ideep/abstract_types.hpp b/include/ideep/abstract_types.hpp
index bfd4de9..19ee62e 100644
--- a/include/ideep/abstract_types.hpp
+++ b/include/ideep/abstract_types.hpp
@@ -64,8 +64,8 @@ const std::map<data_type, int> dt_max_map
 };
 
 enum lowp_kind {
-  u8s8 = 0,
-  s8s8 = 1
+  LOWP_U8S8 = 0,
+  LOWP_S8S8 = 1
 };
 
 enum rnn_kind {
diff --git a/include/ideep/attributes.hpp b/include/ideep/attributes.hpp
index 70861ed..306575c 100644
--- a/include/ideep/attributes.hpp
+++ b/include/ideep/attributes.hpp
@@ -71,7 +71,9 @@ struct attr_t : public dnnl::primitive_attr {
     algorithm alg;
     float scale = 1.0, alpha = 1.0, beta = 0.0;
 
-    auto akind = kind(index);
+    // auto akind = kind(index);
+    auto akind = static_cast<dnnl::primitive::kind>(
+        dnnl_post_ops_get_kind(po.get(), index));
     switch (akind) {
       case kind::sum:
         po.get_params_sum(index, scale);
@@ -106,4 +108,4 @@ struct attr_t : public dnnl::primitive_attr {
 
 }  // namespace ideep
 
-#endif
\ No newline at end of file
+#endif
diff --git a/include/ideep/operators/conv.hpp b/include/ideep/operators/conv.hpp
index ff756a4..256281a 100644
--- a/include/ideep/operators/conv.hpp
+++ b/include/ideep/operators/conv.hpp
@@ -18,13 +18,33 @@ struct convolution_forward : public dnnl::convolution_forward {
                       const dims& padding_l,
                       const dims& padding_r,
                       int groups,
+                      const scale_t& src_scales = scale_t(),
+                      const scale_t& weights_scales = scale_t(),
+                      const scale_t& dst_scales = scale_t(),
                       const attr_t& attr = attr_t(),
                       algorithm aalgorithm = algorithm::convolution_direct,
                       prop_kind aprop_kind = prop_kind::forward,
+                      const lowp_kind alowp_kind = LOWP_U8S8,
                       const engine& aengine = engine::cpu_engine()) {
     compute_impl</*with_bias=*/true>(
-        src, weights, bias, dst_dims, dst, strides, dilates,
-        padding_l, padding_r, groups, attr, aalgorithm, aprop_kind, aengine);
+        src,
+        weights,
+        bias,
+        dst_dims,
+        dst,
+        strides,
+        dilates,
+        padding_l,
+        padding_r,
+        groups,
+        src_scales,
+        weights_scales,
+        dst_scales,
+        attr,
+        aalgorithm,
+        aprop_kind,
+        alowp_kind,
+        aengine);
   }
 
   // fp32 w/o bias
@@ -37,14 +57,34 @@ struct convolution_forward : public dnnl::convolution_forward {
                       const dims& padding_l,
                       const dims& padding_r,
                       int groups,
+                      const scale_t& src_scales = scale_t(),
+                      const scale_t& weights_scales = scale_t(),
+                      const scale_t& dst_scales = scale_t(),
                       const attr_t& attr = attr_t(),
                       algorithm aalgorithm = algorithm::convolution_direct,
                       prop_kind aprop_kind = prop_kind::forward,
+                      const lowp_kind alowp_kind = LOWP_U8S8,
                       const engine& aengine = engine::cpu_engine()) {
     static tensor dummy_bias;
     compute_impl</*with_bias=*/false>(
-        src, weights, dummy_bias, dst_dims, dst, strides, dilates,
-        padding_l, padding_r, groups, attr, aalgorithm, aprop_kind, aengine);
+        src,
+        weights,
+        dummy_bias,
+        dst_dims,
+        dst,
+        strides,
+        dilates,
+        padding_l,
+        padding_r,
+        groups,
+        src_scales,
+        weights_scales,
+        dst_scales,
+        attr,
+        aalgorithm,
+        aprop_kind,
+        alowp_kind,
+        aengine);
   }
 
   // TODO: XPZ: refactor it
@@ -169,30 +209,126 @@ private:
                            const dims& padding_l,
                            const dims& padding_r,
                            int groups,
+                           const scale_t& src_scales,
+                           const scale_t& weights_scales,
+                           const scale_t& dst_scales,
                            const attr_t& attr,
                            algorithm aalgorithm,
                            prop_kind aprop_kind,
+                           const lowp_kind alowp_kind,
                            const engine& aengine) {
+    scale_t dst_scales_in;
+    auto dst_data_type = data_type::f32;
+    tensor::desc src_desc, weights_desc, bias_desc;
+    attr_t op_attr, src_attr, weights_attr, bias_attr;
 
     // make weights and dilates compatible with DNNL
     auto weights_ = weights.make_grouped_weights(groups);
     auto dilates_ = utils::get_compatible_dilates(dilates);
 
+    auto weights_scales_in = weights_.has_scale() ? weights_.get_scale() : weights_scales;
+    if (!weights_scales_in.empty()) {
+      IDEEP_ENFORCE(alowp_kind == LOWP_U8S8 || alowp_kind == LOWP_S8S8, "Unsupported lowp kind");
+      int scale_size = (weights_scales_in.size() > 1) ? dst_dims[1] : 1;
+      auto src_scales_in = src.has_scale() ? src.get_scale()
+        : (src_scales.empty() ? IDEEP_DEF_SCALE : src_scales);
+
+      // determine dst data type
+      if (attr.has_op_kind(kind::sum)) {
+        dst_data_type = dst.get_data_type();
+      } else if (dst_scales.empty() || dst_scales == IDEEP_DEF_SCALE) {
+        dst_data_type = data_type::f32;
+      } else if (attr.non_negitive_output()){
+        dst_data_type = data_type::u8;
+      } else {
+        dst_data_type = data_type::s8;
+      }
+
+      // fill primitive attr
+      scale_t op_scales(scale_size), bias_scales(scale_size);
+      dst_scales_in = (dst_scales.empty() || dst_data_type == data_type::f32)
+        ? IDEEP_DEF_SCALE : dst_scales;
+      for (int i = 0; i < scale_size; i++) {
+        bias_scales[i] = src_scales_in[0] * weights_scales_in[i];
+        op_scales[i] = dst_scales_in[0] / bias_scales[i];
+      }
+
+      if (attr.has_op_kind(kind::sum)) {
+        float sum_scale = dst_scales_in[0] / (dst.has_scale() ? dst.get_scale()[0] : 1.0f);
+        if (attr.has_op_kind(kind::eltwise)) {
+          op_attr = attr_t::residual(sum_scale);
+        } else {
+          op_attr = attr_t::fuse_sum(sum_scale);
+        }
+      } else if (attr.has_op_kind(kind::eltwise)) {
+        op_attr = attr_t::fuse_relu();
+      }
+      op_attr.set_output_scales(IDEEP_OP_SCALE_MASK(scale_size), op_scales);
+      // op_attr.set_int_output_round_mode(round_mode::round_nearest);
+      // if (attr.has_op_kind(kind::sum)) {
+      //   float sum_scale = dst_scales_in[0] / (dst.has_scale() ? dst.get_scale()[0] : 1.0f);
+      //   if (attr.has_op_kind(kind::eltwise)) {
+      //     op_attr.set_post_ops(post_ops::residual(sum_scale));
+      //   } else {
+      //     op_attr.set_post_ops(post_ops::sum(sum_scale));
+      //   }
+      // } else if (attr.has_op_kind(kind::eltwise)) {
+      //   op_attr.set_post_ops(post_ops::relu());
+      // }
+
+      src_desc = {src.get_dims(), alowp_kind == LOWP_U8S8 ? data_type::u8 : data_type::s8};
+      if (src.get_data_type() == data_type::f32) {
+        src_attr = {0 , src_scales_in};
+      }
+
+      weights_desc = {weights_.get_dims(), data_type::s8};
+      if (weights_.get_data_type() == data_type::f32) {
+        weights_attr = {IDEEP_TENSOR_SCALE_MASK(scale_size, (groups > 1)), weights_scales_in};
+      }
+
+      if (with_bias) {
+        bias_desc = {bias.get_dims(), data_type::s32};
+        if (bias.get_data_type() == data_type::f32) {
+          bias_attr = {IDEEP_TENSOR_SCALE_MASK(scale_size, false), bias_scales};
+        }
+      }
+    } else {
+      op_attr = attr;
+
+      src_desc = {src.get_dims(), data_type::f32};
+      if (src.has_scale()) {
+        auto src_scale = src.get_scale();
+        src_scale[0] = 1.0f / src_scale[0];
+        src_attr = {0, src_scale};
+      }
+
+      weights_desc = weights_.get_desc();
+      IDEEP_ENFORCE(weights_.get_data_type() == data_type::f32, "Incorrect data type in weights");
+
+      if (with_bias) {
+        IDEEP_ENFORCE(bias.get_data_type() == data_type::f32, "Incorrect data type in bias");
+        bias_desc = bias.get_desc();
+      }
+    }
+
     // TODO: XPZ: is it ok to use src type as dst type?
     auto dst_desc = attr.has_op_kind(kind::sum)
                         ? dst.get_desc()
-                        : tensor::desc(dst_dims, src.get_data_type());
+                        : tensor::desc(dst_dims, dst_data_type);
     auto pd = get_primitive_desc<with_bias>(
-        src.get_desc(), weights_.get_desc(), bias.get_desc(), dst_desc,
-        strides, dilates_, padding_l, padding_r, attr, aalgorithm,
+        src_desc, weights_desc, bias_desc, dst_desc,
+        strides, dilates_, padding_l, padding_r, op_attr, aalgorithm,
         aprop_kind, aengine);
 
-    auto expected_src = src.reorder_if_differ_in(pd.src_desc());
-    auto expected_weights = weights_.reorder_if_differ_in(pd.weights_desc());
+    auto expected_src = src.reorder_if_differ_in(pd.src_desc(), src_attr);
+    auto expected_weights = weights_.reorder_if_differ_in(pd.weights_desc(), weights_attr);
     dst.reinit_if_necessary(pd.dst_desc());
+    if (!dst_scales.empty() && dst_data_type != data_type::f32) {
+      dst.set_scale(dst_scales_in);
+    }
 
     if (with_bias) {
-      auto expected_bias = bias.reorder_if_differ_in(pd.bias_desc());
+      auto expected_bias = bias.reorder_if_differ_in(pd.bias_desc(), bias_attr);
       super(pd).execute(stream::default_stream(), 
                         {{DNNL_ARG_SRC, expected_src},
                          {DNNL_ARG_WEIGHTS, expected_weights},
@@ -204,6 +340,11 @@ private:
                          {DNNL_ARG_WEIGHTS, expected_weights},
                          {DNNL_ARG_DST, dst}});
     }
+
+    if (attr.non_negitive_output() && dst.get_data_type() == data_type::s8) {
+      tensor::desc dst_u8_desc = dst.get_desc().to_type(data_type::u8);
+      dst.set_desc(dst_u8_desc);
+    }
   }
 };
 
diff --git a/include/ideep/operators/direct_copy.hpp b/include/ideep/operators/direct_copy.hpp
index e0eb941..687931d 100644
--- a/include/ideep/operators/direct_copy.hpp
+++ b/include/ideep/operators/direct_copy.hpp
@@ -8,9 +8,12 @@ struct direct_copy {
   static void compute(const tensor& src, tensor& dst) {
     dst.reinit_if_necessary(src.get_desc());
     src.reorder_to(dst);
+    if (src.has_scale()) {
+      dst.set_scale(src.get_scale());
+    }
   }
 };
 
 }  // namespace ideep
 
-#endif
\ No newline at end of file
+#endif
diff --git a/include/ideep/operators/eltwise.hpp b/include/ideep/operators/eltwise.hpp
index cb5c701..2e0ba70 100644
--- a/include/ideep/operators/eltwise.hpp
+++ b/include/ideep/operators/eltwise.hpp
@@ -14,14 +14,34 @@ struct eltwise_forward : public dnnl::eltwise_forward {
                       float alpha = 0.0,
                       float beta = 0.0,
                       const engine& aengine = engine::cpu_engine()) {
-    auto src_desc = src.get_desc();
-    dst.reinit_if_necessary(src_desc);
+    auto src_in = src;
+    if (aalgorithm != algorithm::eltwise_relu && src.get_data_type() != data_type::f32) {
+      src_in.reinit(src.get_dims(), data_type::f32);
+      IDEEP_ENFORCE(src.has_scale(), "Can not find scales");
+      IDEEP_ENFORCE(src.get_scale().size() == 1, "Incorrect scale size");
+      // auto scale = IDEEP_DEF_SCALE;
+      // scale[0] /= src.get_scale()[0];
+      // treorder_t::compute(src, src_in, {0, scale});
+      src_in.feed_from(src);
+    }
+    auto src_desc = src_in.get_desc();
+    // dst.reinit_if_necessary(src_desc);
 
     auto pd = primitive_desc(
         {aprop_kind, aalgorithm, src_desc, alpha, beta}, aengine);
 
+    if (dst != src) {
+      dst.reinit(src_in.get_descriptor());
+      if (src_in.has_scale()) dst.set_scale(src_in.get_scale());
+    }
+
     super(pd).execute(stream::default_stream(),
-                      {{DNNL_ARG_SRC, src}, {DNNL_ARG_DST, dst}});
+                      {{DNNL_ARG_SRC, src_in}, {DNNL_ARG_DST, dst}});
+
+    if (dst.has_scale() && aalgorithm == algorithm::eltwise_relu && dst.get_data_type() == data_type::s8) {
+      tensor::desc dst_u8_desc = dst.get_desc().to_type(data_type::u8);
+      dst.set_desc(dst_u8_desc);
+    }
   }
 };
 
diff --git a/include/ideep/operators/inner_product.hpp b/include/ideep/operators/inner_product.hpp
index a66dedc..75a9410 100644
--- a/include/ideep/operators/inner_product.hpp
+++ b/include/ideep/operators/inner_product.hpp
@@ -11,20 +11,50 @@ struct inner_product_forward : public dnnl::inner_product_forward {
                       const tensor& weights,
                       const tensor& bias,
                       tensor& dst,
-                      prop_kind aprop_kind = prop_kind::forward,
+                      const scale_t& src_scales = scale_t(),
+                      const scale_t& weights_scales = scale_t(),
+                      const scale_t& dst_scales = scale_t(),
+                      const attr_t& attr = attr_t(),
+                      const prop_kind aprop_kind = prop_kind::forward,
+                      const lowp_kind alowp_kind = LOWP_U8S8,
                       const engine& aengine = engine::cpu_engine()) {
     compute_impl</*with_bias=*/true>(
-        src, weights, bias, dst, aprop_kind, aengine);
+        src,
+        weights,
+        bias,
+        dst,
+        src_scales,
+        weights_scales,
+        dst_scales,
+        attr,
+        aprop_kind,
+        alowp_kind,
+        aengine);
   }
 
   static void compute(const tensor& src,
                       const tensor& weights,
                       tensor& dst,
-                      prop_kind aprop_kind = prop_kind::forward,
+                      const scale_t& src_scales = scale_t(),
+                      const scale_t& weights_scales = scale_t(),
+                      const scale_t& dst_scales = scale_t(),
+                      const attr_t& attr = attr_t(),
+                      const prop_kind aprop_kind = prop_kind::forward,
+                      const lowp_kind alowp_kind = LOWP_U8S8,
                       const engine& aengine = engine::cpu_engine()) {
     static tensor dummy_bias;
     compute_impl</*with_bias=*/false>(
-        src, weights, dummy_bias, dst, aprop_kind, aengine);
+        src,
+        weights,
+        dummy_bias,
+        dst,
+        src_scales,
+        weights_scales,
+        dst_scales,
+        attr,
+        aprop_kind,
+        alowp_kind,
+        aengine);
   }
 
 
@@ -56,7 +86,12 @@ private:
                            const tensor& weights,
                            const tensor& bias,
                            tensor& dst,
-                           prop_kind aprop_kind,
+                           const scale_t& src_scales,
+                           const scale_t& weights_scales,
+                           const scale_t& dst_scales,
+                           const attr_t& attr,
+                           const prop_kind aprop_kind,
+                           const lowp_kind alowp_kind,
                            const engine& aengine) {
     // workaround: src and weights from caffe2 may have different dims.
     // It would be better for caffe2 to do this reshape anyway.
@@ -66,7 +101,18 @@ private:
       new_dims[0] = src.get_dim(0);
       src_.reshape(new_dims);
     }
-    compute_impl_<with_bias>(src_, weights, bias, dst, aprop_kind, aengine);
+    compute_impl_<with_bias>(
+        src_,
+        weights,
+        bias,
+        dst,
+        src_scales,
+        weights_scales,
+        dst_scales,
+        attr,
+        aprop_kind,
+        alowp_kind,
+        aengine);
   }
 
   template <bool with_bias = true>
@@ -74,34 +120,138 @@ private:
                             const tensor& weights,
                             const tensor& bias,
                             tensor& dst,
-                            prop_kind aprop_kind,
+                            const scale_t& src_scales,
+                            const scale_t& weights_scales,
+                            const scale_t& dst_scales,
+                            const attr_t& attr,
+                            const prop_kind aprop_kind,
+                            const lowp_kind alowp_kind,
                             const engine& aengine) {
-    auto src_desc = src.get_desc().to_format_any();
-    auto weights_desc = weights.get_desc().to_format_any();
-    auto bias_desc = bias.get_desc().to_format_any();
-    auto dst_dims = {src.get_dim(0), weights.get_dim(0)};
-    auto dst_desc = tensor::desc(dst_dims, src.get_data_type(), tag::any);
-
+    tensor::desc src_desc, weights_desc, bias_desc;
+    attr_t op_attr, src_attr, weights_attr, bias_attr;
+    scale_t dst_scales_in;
+    auto dst_data_type = data_type::f32;
+    tensor::dims dst_dims;
+
+    auto weights_scales_in =
+        weights.has_scale() ? weights.get_scale() : weights_scales;
+
+    if (!weights_scales_in.empty()) {
+      IDEEP_ENFORCE(
+          alowp_kind == LOWP_U8S8 || alowp_kind == LOWP_S8S8,
+          "Unsupported lowp kind");
+
+      auto src_scales_in = src.has_scale()
+          ? src.get_scale()
+          : (src_scales.empty() ? IDEEP_DEF_SCALE : src_scales);
+
+      src_desc = {src.get_dims(),
+                  alowp_kind == LOWP_U8S8 ? data_type::u8 : data_type::s8,
+                  format_tag::any};
+      if (src.get_data_type() == data_type::f32) {
+        src_attr = {0, src_scales_in};
+      }
+
+      dst_dims = {src_desc.get_dim(0), weights.get_dim(0)};
+      int scale_size = (weights_scales_in.size() > 1) ? dst_dims[1] : 1;
+
+      weights_desc = {weights.get_dims(), data_type::s8, format_tag::any};
+      if (weights.get_data_type() == data_type::f32) {
+        weights_attr = {IDEEP_TENSOR_SCALE_MASK(scale_size, false),
+                        weights_scales_in};
+      }
+
+      // determine dst data type
+      if (dst_scales.empty() || dst_scales == IDEEP_DEF_SCALE) {
+        dst_data_type = data_type::f32;
+      } else if (attr.non_negitive_output()) {
+        dst_data_type = data_type::u8;
+      } else {
+        dst_data_type = data_type::s8;
+      }
+
+      // fill primitive attr
+      scale_t op_scales(scale_size), bias_scales(scale_size);
+      dst_scales_in = (dst_scales.empty() || dst_data_type == data_type::f32)
+          ? IDEEP_DEF_SCALE
+          : dst_scales;
+      for (int i = 0; i < scale_size; i++) {
+        bias_scales[i] = src_scales_in[0] * weights_scales_in[i];
+        op_scales[i] = dst_scales_in[0] / bias_scales[i];
+      }
+      op_attr.set_output_scales(IDEEP_OP_SCALE_MASK(scale_size), op_scales);
+      //  op_attr.set_int_output_round_mode(round_mode::round_nearest);
+
+      if (with_bias) {
+        bias_desc = {bias.get_dims(), data_type::s32, format_tag::any};
+        if (bias.get_data_type() == data_type::f32) {
+          bias_attr = {IDEEP_TENSOR_SCALE_MASK(scale_size, false), bias_scales};
+        }
+      }
+    } else {
+      op_attr = attr;
+      src_desc = {src.get_dims(), data_type::f32, format_tag::any};
+      // src_desc = src.get_desc().to_format_any();
+      if (src.has_scale()) {
+        auto src_scale = src.get_scale();
+        src_scale[0] = 1.0f / src_scale[0];
+        src_attr = {0, src_scale};
+      }
+      dst_dims = {src_desc.get_dim(0), weights.get_dim(0)};
+      weights_desc = weights.get_desc().to_format_any();
+      IDEEP_ENFORCE(
+          weights.get_data_type() == data_type::f32,
+          "Incorrect data type in weights");
+      if (with_bias) {
+        IDEEP_ENFORCE(
+            bias.get_data_type() == data_type::f32,
+            "Incorrect data type in bias");
+        bias_desc = bias.get_desc().to_format_any();
+      }
+    }
+    tensor::desc dst_desc(dst_dims, dst_data_type, format_tag::any);
+    // auto src_desc = src.get_desc().to_format_any();
+    // auto weights_desc = weights.get_desc().to_format_any();
+    // auto bias_desc = bias.get_desc().to_format_any();
+    // auto dst_dims = {src.get_dim(0), weights.get_dim(0)};
+    // auto dst_desc = tensor::desc(dst_dims, src.get_data_type(), tag::any);
+
+    // auto pd = with_bias
+    //     ? primitive_desc({aprop_kind, src_desc, weights_desc,
+    //                       bias_desc, dst_desc}, aengine)
+    //     : primitive_desc({aprop_kind, src_desc, weights_desc,
+    //                       dst_desc}, aengine);
     auto pd = with_bias
-        ? primitive_desc({aprop_kind, src_desc, weights_desc,
-                          bias_desc, dst_desc}, aengine)
-        : primitive_desc({aprop_kind, src_desc, weights_desc,
-                          dst_desc}, aengine);
-
-    auto expected_src = src.reorder_if_differ_in(pd.src_desc());
-    auto expected_weights = weights.reorder_if_differ_in(pd.weights_desc());
+       ? primitive_desc(
+             {aprop_kind, src_desc, weights_desc, bias_desc, dst_desc}, op_attr, aengine)
+       : primitive_desc(
+             {aprop_kind, src_desc, weights_desc, dst_desc}, op_attr, aengine);
+
+    // auto expected_src = src.reorder_if_differ_in(pd.src_desc());
+    // auto expected_weights = weights.reorder_if_differ_in(pd.weights_desc());
+    // dst.reinit_if_necessary(pd.dst_desc());
+    auto expected_src = src.reorder_if_differ_in(pd.src_desc(), src_attr);
+    auto expected_weights = weights.reorder_if_differ_in(pd.weights_desc(), weights_attr);
     dst.reinit_if_necessary(pd.dst_desc());
+    if (!dst_scales.empty() && dst_data_type != data_type::f32) {
+      dst.set_scale(dst_scales_in);
+    }
 
     exec_args args {{DNNL_ARG_SRC, expected_src},
                     {DNNL_ARG_WEIGHTS, expected_weights},
                     {DNNL_ARG_DST, dst}};
 
     if (with_bias){
-      auto expected_bias = bias.reorder_if_differ_in(pd.bias_desc());
+      auto expected_bias = bias.reorder_if_differ_in(pd.bias_desc(), bias_attr);
       args.insert({DNNL_ARG_BIAS, expected_bias});
     }
 
     super(pd).execute(stream::default_stream(), args);
+
+    if (attr.non_negitive_output() && dst.get_data_type() == data_type::s8) {
+      tensor::desc dst_u8_desc = dst.get_desc().to_type(data_type::u8);
+      dst.set_desc(dst_u8_desc);
+    }
   }
 };
 
diff --git a/include/ideep/operators/pool.hpp b/include/ideep/operators/pool.hpp
index 2c052b2..8d25b4e 100644
--- a/include/ideep/operators/pool.hpp
+++ b/include/ideep/operators/pool.hpp
@@ -23,14 +23,26 @@ struct pooling_forward : public dnnl::pooling_forward {
     // workaround: use src.get_desc() once issue intel/mkl-dnn#588 is resolved
     auto src_desc = src._get_unblocked_desc_if_4c_blocked();
     // auto src_desc = src.get_desc();
-    auto dst_desc = tensor::desc(output_sizes, data_type::f32).to_format_any();
+
+    tensor::desc dst_desc;
+    if (src.get_desc().is_nhwc())
+      // workaground: will remove after the issue intel/mkl-dnn#598 is resolved.
+      dst_desc = tensor::desc (output_sizes, src.get_data_type(), tag::nhwc);
+    else
+      dst_desc = tensor::desc(output_sizes, src.get_data_type()).to_format_any();
+
 
     auto pd = primitive_desc(
         {aprop_kind, aalgorithm, src_desc, dst_desc, strides, kernel, padding_l,
          padding_r}, aengine);
 
     auto expected_src = src.reorder_if_differ_in(pd.src_desc());
-    dst.reinit_if_necessary(pd.dst_desc());
+    if (dst != src) {
+      dst.reinit_if_necessary(pd.dst_desc());
+      if (src.has_scale()) {
+        dst.set_scale(src.get_scale());
+      }
+    }
 
     exec_args args {{DNNL_ARG_SRC, expected_src}, {DNNL_ARG_DST, dst}};
     if (with_workspace) {
diff --git a/include/ideep/operators/spliter.hpp b/include/ideep/operators/spliter.hpp
index 421877a..e0376a3 100644
--- a/include/ideep/operators/spliter.hpp
+++ b/include/ideep/operators/spliter.hpp
@@ -39,4 +39,4 @@ struct spliter {
 
 }  // namespace ideep
 
-#endif
\ No newline at end of file
+#endif
diff --git a/include/ideep/operators/sum.hpp b/include/ideep/operators/sum.hpp
index 3b9aafd..974eeca 100644
--- a/include/ideep/operators/sum.hpp
+++ b/include/ideep/operators/sum.hpp
@@ -15,9 +15,16 @@ struct sum : public dnnl::sum {
       // "upcast" vector<tensor::desc> to vector<memory::desc>
       return static_cast<memory::desc>(t.get_desc());
     });
-    auto pd = primitive_desc(scales, input_descs, aengine);
+    bool inplace = (output == inputs[0]);
+    dnnl::sum::primitive_desc pd;
+    if (inplace) {
+      pd = primitive_desc(output.get_desc(), scales, input_descs, aengine);
+    } else {
+      pd = primitive_desc(scales, input_descs, aengine);
+    }
 
-    output.reinit_if_necessary(pd.dst_desc());
+    if (!inplace)
+      output.reinit_if_necessary(pd.dst_desc());
 
     exec_args args {{DNNL_ARG_DST, output}};
     for (int i = 0; i < inputs.size(); ++i) {
@@ -30,4 +37,4 @@ struct sum : public dnnl::sum {
 
 }  // namespace ideep
 
-#endif
\ No newline at end of file
+#endif
